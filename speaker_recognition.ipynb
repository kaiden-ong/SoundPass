{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model to recognize speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training data at: https://www.kaggle.com/datasets/kongaevans/speaker-recognition-dataset\n",
    "\n",
    "Examples: https://keras.io/examples/audio/speaker_recognition_using_cnn/\n",
    "https://www.kaggle.com/code/masoudmzb/gradient-tape-tutorial-audio-proccesing-example/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = os.path.join( \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_SUBFOLDER = \"audio\"\n",
    "NOISE_SUBFOLDER = \"noise\"\n",
    "\n",
    "DATASET_AUDIO_PATH = os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)\n",
    "DATASET_NOISE_PATH = os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)\n",
    "\n",
    "# Percentage of samples to use for validation\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "# Seed to use when shuffling the dataset and the noise\n",
    "SHUFFLE_SEED = 43\n",
    "\n",
    "# The sampling rate to use.\n",
    "# This is the one used in all the audio samples.\n",
    "# We will resample all the noise to this sampling rate.\n",
    "# This will also be the output size of the audio wave samples\n",
    "# (since all samples are of 1 second long)\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# The factor to multiply the noise with according to:\n",
    "#   noisy_sample = sample + noise * prop * scale\n",
    "#      where prop = sample_amplitude / noise_amplitude\n",
    "SCALE = 0.5\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(DATASET_ROOT):\n",
    "    if os.path.isdir(os.path.join(DATASET_ROOT, folder)):\n",
    "        if folder in [AUDIO_SUBFOLDER, NOISE_SUBFOLDER]:\n",
    "            # If folder is `audio` or `noise`, do nothing\n",
    "            continue\n",
    "        elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            # If folder is one of the folders that contains noise samples,\n",
    "            # move it to the `noise` folder\n",
    "            shutil.move(\n",
    "                os.path.join(DATASET_ROOT, folder),\n",
    "                os.path.join(DATASET_NOISE_PATH, folder),\n",
    "            )\n",
    "        else:\n",
    "            # Otherwise, it should be a speaker folder, then move it to\n",
    "            # `audio` folder\n",
    "            shutil.move(\n",
    "                os.path.join(DATASET_ROOT, folder),\n",
    "                os.path.join(DATASET_AUDIO_PATH, folder),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 files belonging to 2 directories\n"
     ]
    }
   ],
   "source": [
    "noise_paths = []\n",
    "for subdir in os.listdir(DATASET_NOISE_PATH):\n",
    "    subdir_path = Path(DATASET_NOISE_PATH) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]\n",
    "if not noise_paths:\n",
    "    raise RuntimeError(f\"Could not find any files at {DATASET_NOISE_PATH}\")\n",
    "print(\n",
    "    \"Found {} files belonging to {} directories\".format(\n",
    "        len(noise_paths), len(os.listdir(DATASET_NOISE_PATH))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Output:\n",
      " \n",
      "Error Output:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "input_file = \"data/noise/other/pink_noise.wav\"\n",
    "output_file = \"data/noise/other/pink_noise_resampled.wav\"\n",
    "\n",
    "# Define your shell command for bash (for Unix-like systems, Git Bash, or WSL)\n",
    "command = f\"ffmpeg -hide_banner -loglevel panic -y -i {input_file} -ar 16000 {output_file}\"\n",
    "\n",
    "\n",
    "# Use WSL to run the bash command\n",
    "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Print the results\n",
    "print(\"Standard Output:\\n\", result.stdout)\n",
    "print(\"Error Output:\\n\", result.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate tf.Tensor(22050, shape=(), dtype=int32)\n",
      "Sampling rate for data\\noise\\other\\exercise_bike.wav is incorrect. Ignoring it\n",
      "sampling rate tf.Tensor(22050, shape=(), dtype=int32)\n",
      "Sampling rate for data\\noise\\other\\pink_noise.wav is incorrect. Ignoring it\n",
      "sampling rate tf.Tensor(16000, shape=(), dtype=int32)\n",
      "sampling rate tf.Tensor(44100, shape=(), dtype=int32)\n",
      "Sampling rate for data\\noise\\_background_noise_\\10convert.com_Audience-Claps_daSG5fwdA7o.wav is incorrect. Ignoring it\n",
      "sampling rate tf.Tensor(22050, shape=(), dtype=int32)\n",
      "Sampling rate for data\\noise\\_background_noise_\\doing_the_dishes.wav is incorrect. Ignoring it\n",
      "sampling rate tf.Tensor(22050, shape=(), dtype=int32)\n",
      "Sampling rate for data\\noise\\_background_noise_\\dude_miaowing.wav is incorrect. Ignoring it\n",
      "sampling rate tf.Tensor(22050, shape=(), dtype=int32)\n",
      "Sampling rate for data\\noise\\_background_noise_\\running_tap.wav is incorrect. Ignoring it\n",
      "Number of noise samples: 60\n"
     ]
    }
   ],
   "source": [
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    print(\"sampling rate\", sampling_rate)\n",
    "    if sampling_rate == SAMPLING_RATE:\n",
    "        # Number of slices of 16000 each that can be generated from the noise sample\n",
    "        slices = int(sample.shape[0] / SAMPLING_RATE)\n",
    "        sample = tf.split(sample[: slices * SAMPLING_RATE], slices)\n",
    "        return sample\n",
    "    else:\n",
    "        print(\"Sampling rate for {} is incorrect. Ignoring it\".format(path))\n",
    "        return None\n",
    "\n",
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)\n",
    "\n",
    "print(\"Number of noise samples:\", len(noises))\n",
    "\n",
    "\n",
    "# print(\n",
    "#     \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n",
    "#         len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n",
    "#     )\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
